<!DOCTYPE html>
<html lang="en">
<head>
<!-- Generated on 2025-07-16 Wed 13:02 -->
<meta charset="utf-8"/>
<title>Empirical Finance - Research Proposal</title>
<meta name="author" content="Jiyan Schneider"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/serif.css" id="theme"/>

<link rel="stylesheet" href="custom.css"/>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide">
<h1>Empirical Finance - Research Proposal</h1><br><h2>Finding Scaling Laws in Financial data</h2><br><h4>Jiyan Schneider</h4><br>Keio University, Graduate school of Economics
</section>
<section id="table-of-contents-section">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#/slide-introduction">Introduction</a></li>
<li><a href="#/slide-Proposal of idea">Proposal of idea</a></li>
<li><a href="#/slide-motivation">Motivation</a></li>
<li><a href="#/slide-background">Background</a>
<ul>
<li><a href="#/slide-initial_scaling_law_research">Initial Scaling law research</a></li>
<li><a href="#/slide-current-research">Current research</a></li>
</ul>
</li>
<li><a href="#/slide-methodology">Methodology</a>
<ul>
<li><a href="#/slide-data">Data</a></li>
<li><a href="#/slide-methods">Methods</a></li>
</ul>
</li>
<li><a href="#/slide-methods-of-evaluatoin">Method of evaluation</a></li>
<li><a href="#/slide-limitations">Limitations and plans</a></li>
<li><a href="#/slide-bibliography">Bibliography</a></li>
</ul>
</div>
</div>
</section>
<section>
<section id="slide-introduction">
<h2 id="introduction">Introduction</h2>
<aside class="notes">
<ul>
<li>Introduction
– “AI progress became predictable once we knew the scaling law.”– Ask yourself: could finance become predictable the same way?</li>

</ul>

</aside>
<ul>
<li>Recent breakthroughs in AI, particularly Large Language Models (LLMs), have been driven by the &ldquo;scaling hypothesis.&rdquo;</li>
<li><b><b>Scaling Hypothesis:</b></b> Performance of a model predictably improves as we increase resources (model size, data, compute).</li>
<li>This relationship often follows a smooth power law, making progress measurable and forecastable.</li>
<li><b><b>Research Question:</b></b> Can similar scaling laws be identified in the domain of quantitative finance?</li>

</ul>


<div id="orgc73e640" class="figure">
<p><img src="assets/scaling_laws_improvement.jpg" alt="scaling_laws_improvement.jpg" height="200px" />
</p>
</div>

<p>
Taken from (<a href="#citeproc_bib_item_4">Kaplan et al. 2020</a>)
</p>
</section>
</section>
<section>
<section id="slide-Proposal of idea">
<h2 id="Proposal of idea">Proposal of idea</h2>
<aside class="notes">
<p>
– We systematically hunt for a power-law L(N,D) in the 10-second mid-price prediction task.
– If it exists, it answers the ROI question forever.
</p>

</aside>
<ul>
<li>This research proposes to systematically investigate the existence of scaling laws in financial forecasting.</li>
<li>We test the hypothesis that a financial model&rsquo;s performance (e.g., predictive accuracy) scales as a power-law with:
<ol>
<li><b><b>Model Size (N):</b></b> The number of parameters in the model.</li>
<li><b><b>Data Size (D):</b></b> The volume of historical data used for training.</li>

</ol></li>
<li>The goal is to fit an empirical formula, similar to those found in LLMs:
\[ L(N, D) \approx E_{\text{irred}} + \frac{A}{N^\alpha} + \frac{B}{D^\beta} \]
where L is the prediction loss.</li>

</ul>
</section>
<section id="slide-results_expected">
<h5 id="results_expected">Results</h5>
<aside class="notes">
<ul>
<li>This slide shows what the output of our resarch would be</li>
<li>This is from Hoffman paper for scaling laws of LLMs. Since this is just a proposal, I will put it here, explain it</li>
<li>so that you could understand what we would get.</li>

</ul>

</aside>

<p>
<img src="assets/Learning predictions.jpg" alt="Learning predictions.jpg" />
Figure taken from (<a href="#citeproc_bib_item_3">Hoffmann et al. 2022</a>)
</p>
</section>
</section>
<section>
<section id="slide-motivation">
<h2 id="motivation">Motivation</h2>
<aside class="notes">
<p>
– This lens already guided $100 M decisions at OpenAI, Google, DeepSeek.
– The same tool can tell us when to buy Compute vs. do data acquisition
</p>
<ul>
<li>We could answer questions like, How much data do we need to achieve our goals?</li>
<li>Do we need more compute given our data?</li>
<li>Is what we want to do even realistically achievable with our data / all available data on the planet</li>
<li>Lastly, its also feasible</li>

</ul>

</aside>
<ul>
<li><b><b>Practical:</b></b> If scaling laws hold, we can optimize resource allocation.
<ul>
<li>Avoids costly trial-and-error in model development.</li>
<li>Allows us to forecast the &ldquo;return on investment&rdquo; for acquiring more data or training larger models.</li>
<li>Informs optimal model design, analogous to how Hoffmann et al. (2022) found smaller models trained on more data were optimal.</li>

</ul></li>
<li><b><b>Theoretical:</b></b>
<ul>
<li>Provides a new framework for understanding the limits of predictability in financial markets.</li>
<li>The &ldquo;irreducible error&rdquo; term (\(E_{irred}\)) in the scaling law could be interpreted as a measure of fundamental market efficiency or noise.</li>

</ul></li>
<li><b><b>Feasible:</b></b>
<ul>
<li>Scaling laws seem to hold even on quite small scales so you don&rsquo;t need a 1024 H100 machines.</li>

</ul></li>

</ul>
</section>
</section>
<section>
<section id="slide-background">
<h2 id="background">Background</h2>
</section>
<section id="slide-initial_scaling_law_research">
<h3 id="initial_scaling_law_research">Initial Scaling law research</h3>
<aside class="notes">
<ul>
<li>Background (Kaplan, left)
– First empirical evidence that language performance scales smoothly with model / data / compute.
– Implied: “train the largest model you can afford.”</li>

<li>Background (Hoffmann, right) – IsoFLOP revelation
– Their famous figure: U-shaped iso-Flops.
– Minimum was 4× smaller model + 4× more data → the cheaper, stronger “Chinchilla.”– Our task: find the financial “Chinchilla.”</li>

</ul>

</aside>
<ul>
<li><b><b>Kaplan et al. (2020), &ldquo;Scaling Laws for Neural Language Models&rdquo;</b></b> (<a href="#citeproc_bib_item_4">Kaplan et al. 2020</a>)
<ul>
<li>First to comprehensively demonstrate that LLM loss scales smoothly as a power-law with model size, dataset size, and training compute.</li>
<li>Their findings suggested that for best performance, model size should be the primary focus of scaling efforts.</li>

</ul></li>
<li><b><b>Hoffmann et al. (2022), &ldquo;Training Compute-Optimal Large Language Models&rdquo;</b></b> (<a href="#citeproc_bib_item_3">Hoffmann et al. 2022</a>)
<ul>
<li>Refined Kaplan&rsquo;s work. By their analysis, for optimal performance under a fixed compute budget, model size and dataset size should be scaled in roughly equal proportion.</li>
<li>Their model, &ldquo;Chinchilla,&rdquo; though much smaller than competitors like Gopher (or GPT-3), outperformed them by being trained on significantly more data.</li>

</ul></li>
<li>We want to apply the methodologies of these papers to a financial context</li>

</ul>
</section>
<section id="slide-current-research">
<h3 id="current-research">Current research</h3>
<aside class="notes">
<ul>
<li>Currently scaling law research is done for new architectures / types of data</li>

</ul>
<p>
This isn&rsquo;t just a theoretical exercise.
</p>
<ul>
<li>Guide massive investments in Large Language Models -&gt; The Kaplan 2020 paper is said to be what inspired OpenAI to try and go for ChatGPT</li>
<li>Hoffman was at google (gemini)</li>
<li>The last author of the Kaplan paper was Amodei (Now at anthropic)</li>

</ul>

</aside>
<ul>
<li>The &ldquo;scaling&rdquo; approach is a proven framework for making progress in complex domains by making it predictable and measurable.</li>
<li>It has been used to:
<ul>
<li>Guide massive investments in Large Language Models. ((<a href="#citeproc_bib_item_4">Kaplan et al. 2020</a>))</li>
<li>Discover optimal model architectures and data-to-model size ratios (<a href="#citeproc_bib_item_3">Hoffmann et al. 2022</a>; <a href="#citeproc_bib_item_2">DeepSeek-AI et al. 2024</a>)</li>
<li>Achieve breakthroughs in computer vision. (<a href="#citeproc_bib_item_7">Zhai et al. 2022</a>)</li>
<li>The existence of bad scaling laws with audio cause pessism and leads people to pivot into new research directions (<a href="#citeproc_bib_item_1">Cuervo and Marxer 2024</a>; <a href="#citeproc_bib_item_5">Maimon et al. 2025</a>)</li>

</ul></li>

<li><b><b>Our goal is to bring these same benefits to quantitative finance:</b></b>
<ul>
<li><b><b>Practical:</b></b> Forecast the ROI of compute/data, optimize resource allocation, and avoid costly trial-and-error.</li>
<li><b><b>Theoretical:</b></b> Create a new framework for measuring market predictability and estimating the &ldquo;irreducible&rdquo; market noise (\(E_{\text{irred}}\)).</li>

</ul></li>

</ul>
</section>
</section>
<section>
<section id="slide-methodology">
<h2 id="methodology">Methodology</h2>
</section>
<section id="slide-data">
<h3 id="data">Data</h3>
<aside class="notes">
<ul>
<li>Considered multiple time horizons, however due to the need for Big data, short time horizons seem better</li>
<li>If we find something on long time horizons, we won&rsquo;t have enough data to scale it infinitely anyways.</li>

</ul>
<p>
– S&amp;P 500 TAQ 2010–2023.
– Task: predict sign and magnitude of ∆ mid-Price over next 10 s from previous 60 s.
– 7 TB compressed = enough samples to actually scale.
</p>

</aside>
<ul>
<li>We use high-frequency trade and quote (TAQ) data for a broad set of US equities (e.g., S&amp;P 500 components).</li>
<li><b><b>Period:</b></b> 2010-2023, providing a large dataset to sample from.</li>
<li><b><b>Prediction Task:</b></b> Predict the sign and magnitude of the mid-price change over the next 10 seconds based on the previous 60 seconds of order book and trade data. This is a simple, well-defined, and computationally tractable task.</li>
<li>Only train for a single Epoch at most</li>
<li>Extensively care that we do not use future data to evaluate our models</li>

</ul>
</section>
<section id="slide-methods">
<h3 id="methods">Methods</h3>
<aside class="notes">
<ul>
<li>IsoFLOP design – one curve per slide
<ol>
<li>Pick total FLOP budget   → horizontal dashed line in slide.</li>
<li>Train 20 models at the same FLOP but different (N,D) splits.</li>
<li>Plot Loss vs. N to get the U-shape.</li>
<li>Repeat for three budgets = three U-curves.</li>
<li>The bottom points trace N_opt(D_opt) → ratio of α/β.</li>

</ol></li>

</ul>

</aside>

<div class="leftcol" id="org466c475">
<p>
Use the ISOFlop approach (Approach 2 from (<a href="#citeproc_bib_item_3">Hoffmann et al. 2022</a>))
</p>
<ul>
<li><b><b>Define Model Architecture:</b></b>
<ul>
<li>A simple, scalable state of the art neural network. (Transformer-based, decoder only, unidirectional)</li>

</ul></li>
<li><b><b>Define Compute Budgets:</b></b></li>
<li><b><b>Pick compute budget:</b></b> number of FLOPs  E.g., \( \{10^{18}, 10^{19}, 10^{20 }\} \) FLOPs</li>
<li><b><b>Model Training &amp; Evaluation:</b></b> Train slighly different models on Slightly different amounts of data, record final loss.</li>
<li><b><b>Analysis:</b></b> Plot the final loss for each model against its size and estimate the log-log relationship</li>
<li><b><b>If possible:</b></b> Train a final big model and log-log relationship prediction to actual performance</li>

</ul>

</div>
</section>
<section id="slide-orga49e3c8">
<h4 id="orga49e3c8">Transformer mdoel</h4>
<aside class="notes">
<ul>
<li>Studied a lot</li>
<li>In finance as well</li>
<li>Felt low risk</li>
<li>Easily can adapt width and height parameters</li>

</ul>

</aside>


<div id="org75bf3db" class="figure">
<p><img src="assets/transformer_arch.jpg" alt="transformer_arch.jpg" height="460px" />
</p>
</div>

<p>
Figure taken from (<a href="#citeproc_bib_item_6">Vaswani et al. 2017</a>)
</p>
</section>
<section id="slide-org3ce2999">
<h4 id="org3ce2999">Isoflop Curve</h4>
<aside class="notes">
<ul>
<li>After the experiment is done I want to plot the isocurves like this.</li>

</ul>

</aside>

<p>
<img src="assets/isoflop.jpg" alt="isoflop.jpg" />
Figure taken from Hoffman
</p>
</section>
</section>
<section>
<section id="slide-methods-of-evaluatoin">
<h2 id="methods-of-evaluatoin">Method of evaluation</h2>
<ul>
<li><i>Forecast error</i>: final cross-entropy vs baseline logit model (y-axis log-transformed).</li>
<li><i>Economic value</i>: out-of-sample Sharpe ratio of a pure signal-driven strategy.</li>
<li>Increasing \( R^{2} \)s in the log-log relationship would validate the scaling hypothesis.</li>
<li>However considering other</li>
<li>We analyze the estimated exponents \( \alpha \) and \( \beta \). These determine the relative importance of model size vs. data size for financial prediction.</li>
<li>As a secondary, economic evaluation, we can construct a simple trading strategy based on the predictions of the best models to gauge their potential profitability (e.g., Sharpe ratio).</li>

</ul>
</section>
</section>
<section>
<section id="slide-limitations">
<h2 id="limitations">Limitations and plans</h2>
<ul>
<li><b><b>Computational Cost:</b></b> Training a large grid of models is resource-intensive.
<ul>
<li><b><b>Plan:</b></b> Start with a smaller-scale pilot study. Utilize university high-performance computing (HPC) resources or cloud credits.</li>

</ul></li>
<li><b><b>Evalution Criteria:</b></b> Is our current criteria \( R^{2} \) actually amenable for these scaling laws?</li>
<li><b><b>Data Non-stationarity:</b></b> Financial markets evolve, which may complicate the scaling relationship.</li>
<li><b><b>Generalizability:</b></b> Results might be specific to our chosen task, data, or model architecture.
<ul>
<li><b><b>Plan:</b></b> If time permits, test a secondary task (e.g., volatility prediction) or a different model family (e.g., an LSTM).</li>

</ul></li>

</ul>
</section>
</section>
<section>
<section id="slide-bibliography">
<h2 id="bibliography">Bibliography</h2>
<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>Cuervo, Santiago, and Ricard Marxer. 2024. <a href="https://doi.org/10.18653/v1/2024.emnlp-main.21">“Scaling Properties of Speech Language Models.</a>” In <i>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</i>, 351–61.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>DeepSeek-AI, Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, et al. 2024. <a href="https://doi.org/10.48550/arXiv.2401.02954">“DeepSeek LLM: Scaling Open-Source Language Models with Longtermism.</a>” arXiv.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, et al. 2022. <a href="https://doi.org/10.48550/arXiv.2203.15556">“Training Compute-Optimal Large Language Models.</a>” arXiv.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. <a href="https://doi.org/10.48550/arXiv.2001.08361">“Scaling Laws for Neural Language Models.</a>” arXiv.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>Maimon, Gallil, Michael Hassid, Amit Roth, and Yossi Adi. 2025. <a href="https://doi.org/10.48550/arXiv.2504.02398">“Scaling Analysis of Interleaved Speech-Text Language Models.</a>” arXiv.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <a href="http://arxiv.org/abs/1706.03762">“Attention Is All You Need.</a>” <i>Corr</i> abs/1706.03762.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>Zhai, Xiaohua, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer. 2022. <a href="https://doi.org/10.1109/cvpr52688.2022.01179">“Scaling Vision Transformers.</a>” In <i>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 1204–13. New Orleans, LA, USA: IEEE.</div>
</div>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/markdown.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/notes/notes.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/search/search.js"></script>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/plugin/zoom/zoom.js"></script>
<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: true,
center: true,
slideNumber: 'c',
rollingLinks: false,
keyboard: true,
mouseWheel: false,
fragmentInURL: true,
hashOneBasedIndex: false,
pdfSeparateFragments: true,
overview: true,

transition: 'linear',
transitionSpeed: 'default',

// Plugins with reveal.js 4.x
plugins: [ RevealMarkdown, RevealNotes, RevealSearch, RevealZoom ],

// Optional libraries used to extend reveal.js
dependencies: [
]

});
</script>
</body>
</html>
